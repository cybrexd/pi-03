{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las Librerias y Modulos necesarias\n",
    "import pandas as pd\n",
    "\n",
    "import sqlalchemy\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de importar las librerias necesarias para Realizar el analisis exploratorio de datos,la normalizacion,limpieza y transformacion de los datos para luego exportarlos\n",
    "\n",
    "Empezando por el dataset provista por la OAIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se lee el csv Dataframe \"AccidentesAviones.csv\" para asi importarlo como dataframe y poder hacer un Analisis profundo del mismo\n",
    "\n",
    "df = pd.read_csv(\"AccidentesAviones.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos columnas que se consideran que no aportan nada al analisis  ni tienen valor como dato\n",
    "\n",
    "df = df.drop([\"Unnamed: 0\",\"flight_no\",\"registration\",\"cn_ln\"],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se limpia la columna hora Utilizando Funciones\n",
    "def limpiar_hora(x):\n",
    "    x = x.replace(\"c \", \"\")\n",
    "    x = x.replace(\"z\", \"\")\n",
    "    x = x.replace(\"c:\", \"\")\n",
    "    x = x.replace(\" \", \"\")\n",
    "    x = x.replace(\";\", \"\")\n",
    "    if x == \"?\":\n",
    "        return (\"00:00\")\n",
    "    else:\n",
    "        if  \":\" not in x:\n",
    "            return(x[:2]+\":\"+x[2:])\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "\n",
    "df[\"HORA declarada\"] = df[\"HORA declarada\"].apply(limpiar_hora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se limpian las columnas relacionadas a los datos de  operador y rutas\n",
    "def limpiar_operador(x):\n",
    "    if x == \"?\":\n",
    "        return (\"Private\")\n",
    "    else:\n",
    "        return x\n",
    "def limpiar_ruta(x):\n",
    "    if x[\"Ruta\"] == \"?\":\n",
    "        return(x[\"route\"])\n",
    "    else:\n",
    "        return  x[\"Ruta\"] \n",
    "def limpiar_route(x):\n",
    "    if x[\"route\"] == \"?\":\n",
    "        return(x[\"Ruta\"])\n",
    "    else:\n",
    "        return x[\"route\"]\n",
    "\n",
    "df[\"OperadOR\"] = df[\"OperadOR\"].apply(limpiar_operador)\n",
    "df[\"Ruta\"] = df.apply(limpiar_ruta,axis=1)\n",
    "df[\"route\"] = df.apply(limpiar_route,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se Simplifican y Ordenan los datos relacionados a pasajeros,tripulacion y fallecidos\n",
    "def limpiar_pas_tri_fal(x):\n",
    "    if x == \"?\":\n",
    "        return (0)\n",
    "    else:\n",
    "        return(x)\n",
    "def supervivientes(df):\n",
    "    return (df[\"Total a Bordo\"] - df[\"cantidad de fallecidos\"])\n",
    "\n",
    "df = df.drop([\"crew_aboard\",\"PASAJEROS A BORDO\",\"passenger_fatalities\",\"crew_fatalities\"],axis=1)\n",
    "df = df.rename(columns={\"all_aboard\":\"Total a Bordo\"})\n",
    "df[\"Total a Bordo\"] = df[\"Total a Bordo\"].apply(limpiar_pas_tri_fal).astype(int)\n",
    "df[\"cantidad de fallecidos\"] = df[\"cantidad de fallecidos\"].apply(limpiar_pas_tri_fal).astype(int)\n",
    "df[\"Supervivientes\"] = df.apply(supervivientes,axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extendemos la informacion Utilizando mas informacion que la provista para expander nuestros datos para el analisis,haciendole un proceso similar al anterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizamos un dataset con el numero de pasajeros transportados en avion a lo largo de los a√±os, rescatando unicamente\n",
    "#Los datos importantes para el analisis\n",
    "df1 = pd.read_csv(r\"C:\\Users\\elpep\\Desktop\\proyecto\\power-bi\\numeros_transporte.csv\")\n",
    "df1 = df1.drop([\"Indicator Name\",\"Indicator Code\",\"Unnamed: 66\",\"Country Name\",\"Country Code\"],axis=1)\n",
    "df1 = df1.fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganizamos el dataset para que asi pueda ser utilizado correctamente en el dashboard\n",
    "\n",
    "df2 = pd.DataFrame({\"Year\": [], \"Total\":[]})\n",
    "anios = list(df1.columns)\n",
    "total = []\n",
    "for elemento in anios:\n",
    "    total.append(int(df1[elemento].sum()))\n",
    "\n",
    "df2 = pd.DataFrame({\"Year\": [], \"Total\":[]})\n",
    "df2[\"Year\"] = anios\n",
    "df2[\"Total\"] = total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente Ingestamos ambos datasets ya limpios y con los datos que nos interesan directamente en nuestra base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Realizamos La conexion  de los dataframes utilizando la libreria SQL Alchemy hacia la DB en mySQL ingestandolos\n",
    "#Directamente dentro de la base de datos para poder trabajarlos\n",
    "conexionstr = \"mysql+pymysql://root:1234@localhost:3306/pi_03\"\n",
    "\n",
    "conexion = create_engine(conexionstr)\n",
    "\n",
    "dbconexion = conexion.connect()\n",
    "\n",
    "df.to_sql(name=\"accidentesaeros\",con=conexion,if_exists=\"replace\",index=False)\n",
    "df2.to_sql(name=\"pasajeros_transportados\",con=conexion,if_exists=\"replace\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c01e3f5d77c63006669fe213228f404fdc42846a61aa9016f2e2e142d4d5c26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
